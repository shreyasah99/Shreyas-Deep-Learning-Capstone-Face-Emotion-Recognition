{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb658c72",
   "metadata": {},
   "source": [
    "The code in this file helps us to open the webcam , detect the faces and with the help of our model detect the emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13b33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ebfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading .h5 file and storing it in my_model3\n",
    "\n",
    "my_model3 = tf.keras.models.load_model('shreyas_scratch_model.h5') #58, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd939be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Haar Classifier is an algorithm which is  trained from many many positive images (with faces) \n",
    "and negatives images (without faces).\n",
    "We download its xml file and import and store it in face_detect.'''\n",
    "\n",
    "\n",
    "\n",
    "face_detect = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be463dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prediction will be number from 0-6 ; to link it to its emotion we created this dictionary.\n",
    "\n",
    "class_labels = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c422d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-c62ec6597bca>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if face_roi is ():                                        # check if face_roi is empty ie. no face detected\n"
     ]
    }
   ],
   "source": [
    "#  load cascade classifier\n",
    "face_detect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
    "\n",
    "    \n",
    "\n",
    "def face_detection(img,size=0.5):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)              # converting image into grayscale\n",
    "    face_roi = face_detect.detectMultiScale(img_gray, 1.3,1)      # ROI (region of interest of detected face, stored as tuple of bottom left and bottom right coordinates) \n",
    "                                                                   \n",
    "    \n",
    "    if face_roi is ():                                        # check if face_roi is empty ie. no face detected\n",
    "        return img\n",
    "\n",
    "    for(x,y,w,h) in face_roi:                                 # iterate through faces and draw rectangle over each face\n",
    "        x = x - 5\n",
    "        w = w + 10\n",
    "        y = y + 7\n",
    "        h = h + 2\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(125,125,10), 1)      # (x,y)- top left point  ; (x+w,y+h)-bottom right point  ;  (125,125,10)-colour of rectangle ; 1- thickness \n",
    "        img_gray_crop = img_gray[y:y+h,x:x+w]                    # croping gray scale image \n",
    "        img_color_crop = img[y:y+h,x:x+w]                        # croping colour image\n",
    "        \n",
    "        \n",
    "        final_image = cv2.resize(img_color_crop, (48,48))      # size of colured image is resized to 224,224\n",
    "        final_image = np.expand_dims(final_image, axis = 0)      # array is expanded by inserting axis at position 0\n",
    "        final_image = final_image/255.0                          # feature scaling of final image\n",
    "    \n",
    "        prediction = my_model3.predict(final_image)              # emotion of the captured image is detected with the help of our model\n",
    "        label=class_labels[prediction.argmax()]                  # we find the label of class which has maximaum probalility \n",
    "        cv2.putText(frame,label, (50,60), cv2.FONT_HERSHEY_SCRIPT_COMPLEX,2, (120,10,200),3)  \n",
    "                                                      # putText is used to draw a detected label on image\n",
    "                                                      # (50,60)-top left coordinate   FONT_HERSHEY_SCRIPT_COMPLEX-font type\n",
    "                                                      # 2-fontscale   (120,10,200)-font colour   3-font thickness\n",
    "\n",
    "\n",
    "    img_color_crop = cv2.flip(img_color_crop, 1)      # fliping the image\n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)                    # capture the video ie. live webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('LIVE', face_detection(frame))          # captured frame will be sent to face_detection function for emotion detection\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0cf06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
